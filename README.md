# ğŸ¤– RAG Chatbot - Sistema de Chat com IA Local

Sistema completo de chatbot com RAG (Retrieval-Augmented Generation) utilizando LLM local (Ollama + Llama3), embeddings vetoriais (PGVector) e interface N8N.

---

## ğŸ“‹ Ãndice

- [CaracterÃ­sticas](#-caracterÃ­sticas)
- [Arquitetura](#-arquitetura)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Uso](#-uso)
- [API](#-api)
- [Tecnologias](#-tecnologias)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [Troubleshooting](#-troubleshooting)
- [Contribuindo](#-contribuindo)
- [LicenÃ§a](#-licenÃ§a)

---

## âœ¨ CaracterÃ­sticas

### ğŸ¯ Funcionalidades Principais

- **Chat Inteligente**: Interface de chat via N8N com memÃ³ria de contexto
- **Upload de Documentos**: Suporte a 9 formatos diferentes
- **RAG (Retrieval-Augmented Generation)**: Respostas baseadas em documentos
- **LLM Local**: Ollama + Llama3 rodando 100% local
- **Scraping AutomÃ¡tico**: Coleta automÃ¡tica de conteÃºdo web
- **Busca Vetorial**: PGVector para similaridade semÃ¢ntica
- **HistÃ³rico Persistente**: Conversas armazenadas no PostgreSQL
- **OCR Integrado**: ExtraÃ§Ã£o de texto de imagens

### ğŸ“„ Formatos Suportados

| Categoria | Formatos |
|-----------|----------|
| Documentos | PDF, DOCX, DOC, TXT |
| Planilhas | XLSX, XLS, CSV |
| ApresentaÃ§Ãµes | PPTX, PPT |
| Imagens (OCR) | JPG, PNG, GIF, BMP, WEBP, TIFF |

### ğŸš€ Tecnologias de IA

- **LLM**: Ollama (Llama 3) - ExecuÃ§Ã£o local, zero custo
- **Embeddings**: HuggingFace all-MiniLM-L6-v2 (384 dimensÃµes)
- **Vector DB**: PostgreSQL + PGVector (IVFFlat index)
- **OCR**: Tesseract (PortuguÃªs + InglÃªs)
- **Framework**: LangChain para orquestraÃ§Ã£o

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USUÃRIO                              â”‚
â”‚                  (Interface N8N)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ Chat + Upload
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  N8N WORKFLOW                            â”‚
â”‚  â€¢ Chat Trigger                                          â”‚
â”‚  â€¢ Conditional Logic (file detection)                    â”‚
â”‚  â€¢ HTTP Request to API                                   â”‚
â”‚  â€¢ Response Display                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”‚ REST API
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             LITESTAR API (Python)                        â”‚
â”‚  Endpoints:                                              â”‚
â”‚  â€¢ POST /chat      â†’ Process & Answer                    â”‚
â”‚  â€¢ POST /scrape    â†’ Web Scraping                        â”‚
â”‚  â€¢ GET  /history   â†’ Chat History                        â”‚
â”‚  â€¢ GET  /sessions  â†’ List Sessions                       â”‚
â”‚  â€¢ GET  /documents â†’ List Documents                      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       â”‚ Embeddings           â”‚ LLM
       â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HuggingFace  â”‚      â”‚     OLLAMA      â”‚
â”‚  Embeddings  â”‚      â”‚   (Llama 3)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Store Vectors
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          POSTGRESQL + PGVECTOR                           â”‚
â”‚  Tables:                                                 â”‚
â”‚  â€¢ documents   â†’ Metadata                                â”‚
â”‚  â€¢ chunks      â†’ Text + Embeddings (vector 384)          â”‚
â”‚  â€¢ chat_history â†’ Conversation History                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ PrÃ©-requisitos

### Software NecessÃ¡rio

- **Docker** (20.10+) e **Docker Compose** (2.0+)
- **Git** (para clonar o repositÃ³rio)
- **8GB RAM** mÃ­nimo (recomendado: 16GB)
- **10GB** espaÃ§o em disco livre

### Portas Utilizadas

| ServiÃ§o | Porta | DescriÃ§Ã£o |
|---------|-------|-----------|
| N8N | 5678 | Interface web |
| API | 8000 | Backend REST |
| PostgreSQL | 5433 | Banco de dados |
| Ollama | 11434 | LLM Server |

---

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/tyago1413/rag-chatbot.git
cd rag-chatbot
```

### 2. Configure as VariÃ¡veis de Ambiente

```bash
# Editar se necessÃ¡rio (opcional)
nano .env
```

**Principais variÃ¡veis:**
```bash
# URL para scraping automÃ¡tico
SCRAPE_URL=https://pt.wikipedia.org/wiki/Intelig%C3%AAncia_artificial

# Modelo de embeddings
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ConfiguraÃ§Ãµes RAG
TOP_K=5
MAX_CONTEXT_CHARS=2000
CHUNK_SIZE=500
```

### 3. Inicialize o Sistema

```bash
# Build das imagens e iniciar todos os serviÃ§os
docker-compose up -d --build

# Ver logs em tempo real
docker-compose logs -f
```

**â±ï¸ Primeira inicializaÃ§Ã£o:** O download do modelo Llama3 (~4GB) pode levar 10-30 minutos dependendo da sua internet.

### 4. Aguarde a InicializaÃ§Ã£o

```bash
# Verificar status dos containers
docker-compose ps

# Todos devem estar "healthy"
# NAME          STATUS
# n8n           Up (healthy)
# rag-api       Up (healthy)
# postgres      Up (healthy)
# ollama        Up (healthy)
```

### 5. Importe o Workflow N8N

1. Acesse http://localhost:5678
2. VÃ¡ em **Workflows** â†’ **Import from File**
3. Selecione `RAG_Chatbot.json`
4. Ative o workflow (botÃ£o "Active")

---

## ğŸ’» Uso

### Via N8N (Interface GrÃ¡fica)

#### Chat Simples
1. Abra o workflow no N8N
2. Clique em "Test Workflow"
3. Digite sua pergunta
4. Aguarde a resposta

#### Upload de Documento
1. Clique no Ã­cone ğŸ“ (clipe)
2. Selecione um arquivo
3. Digite uma pergunta sobre o arquivo (opcional)
4. Envie!

**Exemplo:**
```
Arquivo: relatorio_vendas.pdf
Pergunta: "Qual foi o total de vendas no Q3?"
```

### Via API (REST)

#### Pergunta Simples

```bash
curl -X POST http://localhost:8000/chat \
  -F "question=O que Ã© inteligÃªncia artificial?" \
  -F "session_id=user123"
```

#### Upload + Pergunta

```bash
curl -X POST http://localhost:8000/chat \
  -F "question=Resuma este documento" \
  -F "session_id=user123" \
  -F "file=@documento.pdf"
```

#### Scraping Manual

```bash
curl -X POST http://localhost:8000/scrape \
  -F "url=https://example.com/artigo"
```

---

## ğŸ“¡ API

### Endpoints Principais

#### POST /chat
Envia mensagem e/ou arquivo para processamento.

**ParÃ¢metros:**
- `question` (string): Pergunta do usuÃ¡rio
- `session_id` (string, opcional): ID da sessÃ£o
- `file` (binary, opcional): Arquivo para processar

**Resposta:**
```json
{
  "status": "success",
  "answer": "Resposta gerada pela IA...",
  "sources": [
    {
      "title": "documento.pdf",
      "source": "upload:documento.pdf",
      "similarity": 0.89
    }
  ],
  "session_id": "user123",
  "context_size": 1500
}
```

#### POST /scrape
Realiza scraping de uma URL.

**ParÃ¢metros:**
- `url` (string, opcional): URL para scraping

**Resposta:**
```json
{
  "status": "success",
  "message": "Scraping concluÃ­do com sucesso",
  "document_id": "uuid...",
  "url": "https://example.com"
}
```

#### GET /history/{session_id}
Consulta histÃ³rico de uma sessÃ£o.

**Resposta:**
```json
{
  "status": "success",
  "session_id": "user123",
  "message_count": 10,
  "messages": [
    {
      "turn": 1,
      "role": "user",
      "content": "OlÃ¡!",
      "created_at": "2024-01-15 10:30:00"
    }
  ]
}
```

#### GET /sessions
Lista todas as sessÃµes.

#### GET /documents
Lista todos os documentos processados.

#### GET /health
Health check da API.

---

## ğŸ”§ Tecnologias

### Backend
- **Framework**: Litestar 2.12.1
- **LLM Orchestration**: LangChain 0.3.7
- **Embeddings**: Sentence Transformers 3.3.1
- **Database**: psycopg2-binary 2.9.10
- **Vector Extension**: pgvector 0.3.6
- **Document Processing**: PyPDF2, pdfplumber, python-docx, python-pptx
- **OCR**: pytesseract 0.3.10
- **Scraping**: BeautifulSoup4, httpx

### Infraestrutura
- **Container**: Docker + Docker Compose
- **Web Server**: Uvicorn (ASGI)
- **Database**: PostgreSQL 16 + PGVector
- **LLM**: Ollama (Llama 3)
- **Workflow**: N8N

### IA/ML
- **LLM**: Meta Llama 3 (via Ollama)
- **Embeddings**: all-MiniLM-L6-v2 (384 dims)
- **Vector Search**: IVFFlat (cosine similarity)
- **OCR Engine**: Tesseract 4.x

---

## ğŸ“ Estrutura do Projeto

```
rag-chatbot/
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ .env                        # VariÃ¡veis de ambiente
â”œâ”€â”€ RAG_Chatbot.json            # Workflow N8N
â”‚
â”œâ”€â”€ api/                        # Backend Python
â”‚   â”œâ”€â”€ Dockerfile              # Container da API
â”‚   â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”‚   â”œâ”€â”€ main.py                 # Endpoints da API
â”‚   â”œâ”€â”€ config.py               # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ database.py             # ConexÃ£o PostgreSQL
â”‚   â”‚
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â”œâ”€â”€ rag_service.py         # LÃ³gica RAG
â”‚       â”‚   â””â”€â”€ scraper_service.py     # Web scraping
â”‚       â”‚
â”‚       â””â”€â”€ utils/
â”‚           â””â”€â”€ document_processor.py   # Processamento de docs
â”‚
â””â”€â”€ db/
    â””â”€â”€ init/
        â””â”€â”€ 010_schema_rag.sql  # Schema inicial do banco
```

---

## ğŸ› Troubleshooting

### Problema: Containers nÃ£o sobem

**SoluÃ§Ã£o:**
```bash
# Limpar containers antigos
docker-compose down -v

# Rebuild
docker-compose build --no-cache

# Subir novamente
docker-compose up -d
```

### Problema: API retorna erro 500

**Verificar logs:**
```bash
docker-compose logs api

# PossÃ­veis causas:
# - Modelo Ollama nÃ£o baixado ainda
# - PostgreSQL nÃ£o iniciou
# - Falta de memÃ³ria
```

**SoluÃ§Ã£o:**
```bash
# Aguardar modelo baixar
docker-compose logs -f ollama-init

# Verificar healthcheck
curl http://localhost:8000/health
```

### Problema: OCR nÃ£o funciona

**Causa:** Tesseract nÃ£o instalado no container

**SoluÃ§Ã£o:**
```dockerfile
# No Dockerfile, verificar se tem:
RUN apt-get update && apt-get install -y \
    tesseract-ocr \
    tesseract-ocr-por \
    libtesseract-dev
```

### Problema: Respostas muito lentas

**Causas comuns:**
1. **Primeira execuÃ§Ã£o** - Modelo precisa carregar (normal)
2. **Pouca RAM** - Ollama precisa ~4GB
3. **CPU lenta** - LLM local Ã© computacionalmente intensivo

**SoluÃ§Ãµes:**
- Aguardar "warm-up" (primeira resposta Ã© sempre lenta)
- Aumentar RAM alocada ao Docker
- Usar GPU (configurar no docker-compose)
- Reduzir `num_predict` em config.py

### Problema: N8N nÃ£o conecta na API

**Verificar rede:**
```bash
# Dentro do N8N
docker-compose exec n8n ping api

# Se nÃ£o pingar, verificar network
docker network inspect imparprojeto_backend
```

---

## ğŸ“Š Monitoramento

### Ver Logs

```bash
# Todos os serviÃ§os
docker-compose logs -f

# ServiÃ§o especÃ­fico
docker-compose logs -f api
docker-compose logs -f ollama
docker-compose logs -f postgres
```

### Verificar SaÃºde dos ServiÃ§os

```bash
# Health check API
curl http://localhost:8000/health

# Status containers
docker-compose ps

# Uso de recursos
docker stats
```

### Consultar Banco de Dados

```bash
# Conectar no PostgreSQL
docker-compose exec postgres psql -U impar -d impar

# Queries Ãºteis
SELECT COUNT(*) FROM documents;
SELECT COUNT(*) FROM chunks;
SELECT COUNT(*) FROM chat_history;

# Ver documentos
SELECT id, title, source, created_at FROM documents ORDER BY created_at DESC LIMIT 5;

# Ver sessÃµes
SELECT session_id, COUNT(*) as msg_count 
FROM chat_history 
GROUP BY session_id;
```

---

## ğŸ¯ Boas PrÃ¡ticas

### Para Melhores Respostas

1. **Seja especÃ­fico nas perguntas**
   - âŒ "Vendas?"
   - âœ… "Qual foi o total de vendas no Q3 de 2023?"

2. **Use o contexto da conversa**
   - O sistema mantÃ©m memÃ³ria entre mensagens
   - VocÃª pode fazer perguntas de acompanhamento

3. **Para documentos grandes**
   - Divida em seÃ§Ãµes menores se possÃ­vel
   - FaÃ§a perguntas especÃ­ficas sobre partes do documento

4. **Para OCR**
   - Use imagens nÃ­tidas e com boa resoluÃ§Ã£o
   - Textos retos (nÃ£o inclinados) funcionam melhor

### Performance

1. **Primeira mensagem sempre Ã© mais lenta** (~30s)
   - Modelo precisa carregar na memÃ³ria
   - Subsequentes sÃ£o mais rÃ¡pidas (~5-10s)

2. **Documentos grandes** (>10MB)
   - Aumentar timeout no N8N
   - Considerar dividir o arquivo

3. **Muitos documentos no banco**
   - Limpar documentos antigos periodicamente
   - Usar filtros por sessÃ£o

---

## ğŸ” SeguranÃ§a

### ProduÃ§Ã£o

Para ambiente de produÃ§Ã£o, implemente:

1. **AutenticaÃ§Ã£o**
   - API Keys na API
   - Login no N8N
   - JWT tokens

2. **HTTPS**
   - Certificados SSL
   - Reverse proxy (nginx)

3. **Rate Limiting**
   - Limite de requisiÃ§Ãµes por IP
   - Throttling

4. **SanitizaÃ§Ã£o**
   - ValidaÃ§Ã£o de inputs
   - Escape de SQL
   - Limpeza de uploads

5. **Secrets**
   - Use Docker secrets
   - NÃ£o commite .env
   - Rotate credenciais

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

---

## ğŸ‘¥ Autores

- **Tiago MendonÃ§a** - *Trabalho Inicial* - [GitHub](https://github.com/tyago1413)

---

## ğŸ™ Agradecimentos

- [Anthropic](https://anthropic.com) - LangChain
- [Meta](https://ai.meta.com) - Llama 3
- [Ollama](https://ollama.ai) - LLM local
- [N8N](https://n8n.io) - Workflow automation
- [PostgreSQL](https://postgresql.org) - Database
- [HuggingFace](https://huggingface.co) - Embeddings

---

## ğŸ“ Suporte

Para dÃºvidas ou problemas:

- ğŸ“§ Email: tyago_art@hotmail.com
- ğŸ’¬ Issues: [GitHub Issues](https://github.com/tyago1413/rag-chatbot/issues)

---

<p align="center">
  Feito com â¤ï¸ usando Python, Docker, Claude.ia, e muito cafÃ© â˜•
</p>